{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be0212fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydrake.all import (\n",
    "    Simulator,\n",
    "    StartMeshcat,\n",
    "    DiagramBuilder,\n",
    ")\n",
    "from manipulation import FindResource, running_as_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cd9f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manipulation.station import (\n",
    "    AddPointClouds,\n",
    "    AppendDirectives,\n",
    "    LoadScenario,\n",
    "    MakeHardwareStation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0808a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tidy_spot_planner import TidySpotPlanner\n",
    "from navigation.map_helpers import PointCloudProcessor\n",
    "from navigation.path_planning import DynamicPathPlanner\n",
    "from controller.spot_controller import SpotController"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd890207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from perception.ObjectDetector import ObjectDetector\n",
    "from grasping.GraspSelector import GraspSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3907cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import logging\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b003ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e497c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA memory management\n",
    "register_signal_handlers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a157263",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter out Drake warnings ###\n",
    "logger = logging.getLogger('drake')\n",
    "logger.addFilter(DrakeWarningFilter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "576d04af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use AnyGrasp (TODO: add to args later)\n",
    "use_anygrasp = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60e7290a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:drake:Meshcat listening for connections at http://localhost:7000\n",
      "WARNING:drake:warning: Material file [ d1ba9ca4-2b6a-4a41-bf87-ecb623e71c74.mtl ] not found in a path : /home/mtrang/Documents/mit/manipulation/project/6.4212-TidySpot/objects\n",
      "Failed to load material file(s). Use default material.\n",
      "\n",
      "WARNING:drake:Meshcat: An obj referenced a material library 'd1ba9ca4-2b6a-4a41-bf87-ecb623e71c74.mtl' that Meshcat could not open; no materials will be included. Obj: '/home/mtrang/Documents/mit/manipulation/project/6.4212-TidySpot/objects/table.obj'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: IDLE -> EXPLORE\n",
      "Exploring environment...\n",
      "TODO: Actually implement this\n",
      "Exploring area at (-1, 5, 0.0)\n",
      "Exploring area at (-1, 5, 0.0)\n",
      "Exploring area at (-1, 5, 0.0)\n",
      "Exploring area at (-1, 5, 0.0)\n",
      "Exploring area at (-1, 5, 0.0)\n",
      "Exploring area at (-1, 5, 0.0)\n",
      "Exploring area at (-1, 5, 0.0)\n",
      "Exploring area at (-1, 5, 0.0)\n",
      "Exploring area at (-1, 5, 0.0)\n",
      "Exploring area at (-1, 5, 0.0)\n",
      "Exploring area at (-1, 5, 0.0)\n",
      "Exploring area at (-1, 5, 0.0)\n",
      "Exploring area at (-1, 5, 0.0)\n",
      "Exploring area at (-1, 5, 0.0)\n",
      "Exploring area at (-1, 5, 0.0)\n",
      "Exploring area at (-1, 5, 0.0)\n",
      "Exploring area at (-1, 5, 0.0)\n",
      "Exploring area at (-1, 5, 0.0)\n",
      "Exploring area at (-1, 5, 0.0)\n",
      "Cleaning up resources...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtrang/Documents/mit/manipulation/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ### Start the visualizer ###\n",
    "    meshcat = StartMeshcat()\n",
    "    meshcat.AddButton(\"Stop meshcat\")\n",
    "\n",
    "    ### Diagram setup ###\n",
    "    builder = DiagramBuilder()\n",
    "    scenario = LoadScenario(\n",
    "        filename=\"robots/spot_with_arm_and_floating_base_actuators_aligned_cameras.scenario.yaml\"\n",
    "    )\n",
    "\n",
    "    camera_names = []\n",
    "    image_size = None\n",
    "\n",
    "    # Enable depth images for all cameras and collect camera names (BUG: False by default?)\n",
    "    for camera_name, camera_config in scenario.cameras.items():\n",
    "        camera_config.depth = True\n",
    "        camera_names.append(camera_name)\n",
    "\n",
    "        if image_size is None:\n",
    "            image_size = (camera_config.width, camera_config.height)\n",
    "\n",
    "    ### Add objects to scene ###\n",
    "    scenario = AppendDirectives(scenario, filename=\"objects/added_object_directives.yaml\")\n",
    "\n",
    "    station = builder.AddSystem(MakeHardwareStation(\n",
    "        scenario=scenario,\n",
    "        meshcat=meshcat,\n",
    "        parser_preload_callback=lambda parser: parser.package_map().PopulateFromFolder(os.getcwd())\n",
    "    ))\n",
    "\n",
    "    ### Add pointclouds ###\n",
    "    to_point_cloud = AddPointClouds(scenario=scenario, station=station, builder=builder) # Add meshcat to parameter list to visualize PCDs (WARNING: loads but crashes after a while!)\n",
    "\n",
    "    ### Get subsystems ###\n",
    "    scene_graph = station.GetSubsystemByName(\"scene_graph\")\n",
    "    plant = station.GetSubsystemByName(\"plant\")\n",
    "\n",
    "    # Instantiate ObjectDetector with station and camera_names\n",
    "    object_detector = builder.AddSystem(ObjectDetector(station, camera_names, image_size))\n",
    "    object_detector.set_name(\"object_detector\")\n",
    "    object_detector.connect_cameras(station, builder)\n",
    "\n",
    "    # Instantiate GraspSelector with use_anygrasp\n",
    "    grasp_selector = builder.AddSystem(GraspSelector(use_anygrasp))\n",
    "    grasp_selector.set_name(\"grasp_selector\")\n",
    "\n",
    "    # Add point cloud processor for path planner\n",
    "    point_cloud_processor = builder.AddSystem(PointCloudProcessor(station, camera_names, to_point_cloud, resolution=0.1, robot_radius=0.1))\n",
    "    point_cloud_processor.set_name(\"point_cloud_processor\")\n",
    "    point_cloud_processor.connect_point_clouds(station, builder)\n",
    "\n",
    "    # Add path planner and mapper\n",
    "    dynamic_path_planner = builder.AddSystem(DynamicPathPlanner(station, point_cloud_processor, np.array([0,0,0]), resolution=0.1, robot_radius=0.1))\n",
    "    dynamic_path_planner.set_name(\"dynamic_path_planner\")\n",
    "    dynamic_path_planner.connect_processor(station, builder)\n",
    "\n",
    "    # Add controller\n",
    "    controller = builder.AddSystem(SpotController(plant, use_teleop=False, meshcat=meshcat))\n",
    "\n",
    "    # Add Finite State Machine = TidySpotPlanner\n",
    "    tidy_spot_planner = builder.AddSystem(TidySpotPlanner(plant, dynamic_path_planner, controller))\n",
    "    tidy_spot_planner.set_name(\"tidy_spot_planner\")\n",
    "    tidy_spot_planner.connect_components(builder, station)\n",
    "\n",
    "    ### Build and visualize diagram ###\n",
    "    diagram = builder.Build()\n",
    "    context = diagram.CreateDefaultContext()\n",
    "    diagram.set_name(\"tidyspot_diagram\")\n",
    "    export_diagram_as_svg(diagram, \"diagram.svg\")\n",
    "\n",
    "    ### Simulation setup ###\n",
    "    simulator = Simulator(diagram)\n",
    "    context = simulator.get_mutable_context()\n",
    "\n",
    "    ### Get subsystem contexts ###\n",
    "    station_context = station.GetMyMutableContextFromRoot(context)\n",
    "    plant_context = plant.GetMyMutableContextFromRoot(context)\n",
    "    object_detector_context = object_detector.GetMyMutableContextFromRoot(context)\n",
    "    # controller_context = controller.GetMyMutableContextFromRoot(context)\n",
    "\n",
    "    ### Set initial Spot state ###\n",
    "    x0 = station.GetOutputPort(\"spot.state_estimated\").Eval(station_context)\n",
    "    station.GetInputPort(\"spot.desired_state\").FixValue(station_context, x0)\n",
    "\n",
    "    ### Run simulation ###\n",
    "    simulator.set_target_realtime_rate(1)\n",
    "    simulator.set_publish_every_time_step(True)\n",
    "\n",
    "    meshcat.Flush()  # Wait for the large object meshes to get to meshcat.\n",
    "\n",
    "    # meshcat.StartRecording()\n",
    "    simulator.AdvanceTo(2.0)\n",
    "\n",
    "    ################\n",
    "    ### TESTZONE ###\n",
    "    ################\n",
    "\n",
    "    # # Display all camera images\n",
    "    # object_detector.display_all_camera_images(object_detector_context)\n",
    "\n",
    "    # # Display single image\n",
    "    # color_image = object_detector.get_color_image(\"frontleft\", object_detector_context).data # Get color image from frontleft camera\n",
    "    # plt.imshow(color_image)\n",
    "    # plt.show()\n",
    "\n",
    "    # # Test anygrasp on frontleft camera\n",
    "    # grasp_selector.test_anygrasp_frontleft_pcd(to_point_cloud, context)\n",
    "\n",
    "    # # Keep meshcat alive\n",
    "    # meshcat.PublishRecording()\n",
    "\n",
    "    while not meshcat.GetButtonClicks(\"Stop meshcat\"):\n",
    "        pass\n",
    "finally:\n",
    "    cleanup_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c1ebb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
